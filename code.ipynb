{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ[\"SPARK_HOME\"] = '/usr/hdp/current/spark-client'\n",
    "sys.path.insert(0, os.path.join(os.environ[\"SPARK_HOME\"], 'python'))\n",
    "\n",
    "# import package\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.ui.port\", 9568)\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext =SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import sql\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import avg\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data files\n",
    "review = pd.read_csv('yelp_review.csv')\n",
    "business = pd.read_csv('yelp_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing non-food or restaurant businesses\n",
    "business = business[map(lambda x: \"Restaurant\" in x or \"Food\" in x,business['categories'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sanitizing 'Text' Field\n",
    "review['text'] = review['text'].replace('\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Joining Review to Business table\n",
    "combined = business.merge(review, on='business_id', how='inner', sort=False)\n",
    "combined['stars_business']=combined['stars_x']\n",
    "combined['stars_review']=combined['stars_y']\n",
    "combined = combined[['business_id','name','stars_business','categories','review_id','stars_review','text','useful','funny','cool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writing to CSV\n",
    "combined.to_csv('yelp_combined_ns.csv',index = False, sep='^',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all just being over both through yourselves its before o hadn herself ll had should to only won under ours has do them his very they not during now him nor d did didn this she each further where few because doing some hasn are our ourselves out what for while re does above between mustn t be we who were here shouldn hers by on about couldn of against s isn or own into yourself down mightn wasn your from her their aren there been whom too wouldn themselves weren was until more himself that but don with than those he me myself ma these up will below ain can theirs my and ve then is am it doesn an as itself at have in any if again no when same how other which you shan needn haven after most such why a off i m yours so y the having once'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = list(set(stopwords.words('english')))\n",
    "\n",
    "str1 = str(' '.join(sw))\n",
    "str2 = 'is am are was were have has had and the is has ive 1 2 3 4 5 6 7 8 9 0‘ourselves’, ‘hers’, ‘between’, ‘yourself’, ‘but’, ‘again’, ‘there’, ‘about’, ‘once’, ‘during’, ‘out’, ‘very’, ‘having’, ‘with’, ‘they’, ‘own’, ‘an’, ‘be’, ‘some’, ‘for’, ‘do’, ‘its’, ‘yours’, ‘such’, ‘into’, ‘of’, ‘most’, ‘itself’, ‘other’, ‘off’, ‘is’, ‘s’, ‘am’, ‘or’, ‘who’, ‘as’, ‘from’, ‘him’, ‘each’, ‘the’, ‘themselves’, ‘until’, ‘below’, ‘are’, ‘we’, ‘these’, ‘your’, ‘his’, ‘through’, ‘don’, ‘nor’, ‘me’, ‘were’, ‘her’, ‘more’, ‘himself’, ‘this’, ‘down’, ‘should’, ‘our’, ‘their’, ‘while’, ‘above’, ‘both’, ‘up’, ‘to’, ‘ours’, ‘had’, ‘she’, ‘all’, ‘no’, ‘when’, ‘at’, ‘any’, ‘before’, ‘them’, ‘same’, ‘and’, ‘been’, ‘have’, ‘in’, ‘will’, ‘on’, ‘does’, ‘yourselves’, ‘then’, ‘that’, ‘because’, ‘what’, ‘over’, ‘why’, ‘so’, ‘can’, ‘did’, ‘not’, ‘now’, ‘under’, ‘he’, ‘you’, ‘herself’, ‘has’, ‘just’, ‘where’, ‘too’, ‘only’, ‘myself’, ‘which’, ‘those’, ‘i’, ‘after’, ‘few’, ‘whom’, ‘t’, ‘being’, ‘if’, ‘theirs’, ‘my’, ‘against’, ‘a’, ‘by’, ‘doing’, ‘it’, ‘how’, ‘further’, ‘was’, ‘here’, ‘than’'\n",
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_category(s1,s2,s3):\n",
    "\n",
    "    s1=s1.encode(\"utf-8\")\n",
    "    s2=s2.encode(\"utf-8\")\n",
    "    s3=s3.encode(\"utf-8\")\n",
    "    s1=s1.strip()\n",
    "    s2=s2.strip()\n",
    "    s3=s3.strip()\n",
    "    \n",
    "    if s1 == 'useful' : \n",
    "        return u'useful'\n",
    "    elif int(s1) > int(s2) and int(s1) > int(s3) :\n",
    "        return 'useful'\n",
    "    elif int(s2) > int(s1) and int(s2) > int(s3) :\n",
    "        return 'funny'\n",
    "    elif int(s3) > int(s2) and int(s3) > int(s1) :\n",
    "        return 'cool'\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "    \n",
    "#    s = re.sub(r'\\\\n',r'', re.sub(r'\\\\x[0-9A-Fa-f]+',r'', s))\n",
    "#    s = (re.sub(r'@','',s)).replace('RT','')\n",
    "#    s = ((s.lstrip('b\\'')).replace('\\'', '')).replace('\"', '')\n",
    "#    return ((s.split(' ')))\n",
    "\n",
    "\n",
    "def string_len(s):\n",
    "\n",
    "    s=s.encode(\"utf-8\")\n",
    "    s= s.strip()\n",
    "    s= s.lower()\n",
    "    s = re.sub(r'\\\\n',r'', re.sub(r'\\\\x[0-9A-Fa-f]+',r'', s))\n",
    "    s = (re.sub(r'@','',s)).replace('RT','')\n",
    "    s = ((s.lstrip('b\\'')).replace('\\'', '')).replace('\"', '').replace(' .','')\n",
    "    s = (s.split(' '))\n",
    "    final = []\n",
    "    for each in  s:\n",
    "        if each != '' :\n",
    "            if each not in str1 :\n",
    "                if each not in str2:\n",
    "                    final.append(each)\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ".filter(lambda x: \"funny\" in x[0][0])\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[4] at parallelize at PythonRDD.scala:423\n"
     ]
    }
   ],
   "source": [
    "lines=sc.textFile(\"hdfs:///data/MSA_8050_Spring_18/proj08/yelp_combined_ns.csv\" , use_unicode = 'False').map(lambda line: line.split(\"^\"))\\\n",
    "            .map(lambda line: (review_category(line[7],line[8],line[9]),string_len(line[6])))\\\n",
    "            .flatMap(lambda x: [((x[0],str(i)), 1) for i in x[1] ] )\\\n",
    "            .filter(lambda x: \"none\" not in x[0][0])\n",
    "\n",
    "#table2 = table1.filter(lambda x: \"TEXT\" in x[12])\n",
    "lines.take(5000)\n",
    "\n",
    "lines1=sc.parallelize(lines.take(50000))\n",
    "print(lines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split3 = lines1.reduceByKey(lambda accum, n: accum + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "split5 = split3.map(lambda x : (x[0][0],x[0][1])).sortBy(lambda x: (x[0][0]), ascending = False)\n",
    "split6 = split5.reduceByKey(lambda a,b : a+','+str(b)).sortBy(lambda x: (x[0]), ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool catogery: made tortillas right lived mileage slice corndogs someone fee attended spicy cons cabinets used milestones\n",
      "funny catogery: response switching meal complain find appears appreciated arm side correct 815 asked thinks options oily\n",
      "useful catogery: picadillo 20s pastas par ironically adorned television 1320 ceiling warmed shut begin lightbulbs non notice\n"
     ]
    }
   ],
   "source": [
    "for i in split6:\n",
    "    str1 = i[1]\n",
    "    str1.split(',')\n",
    "    b = (str1.split(',')[0:15])\n",
    "    final = []\n",
    "    for each in  b:\n",
    "        if each != '':\n",
    "            final.append(each)\n",
    "    print(str(i[0]) + \" category: \" + ' '.join(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 words for different Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ[\"SPARK_HOME\"] = '/usr/hdp/current/spark-client'\n",
    "sys.path.insert(0, os.path.join(os.environ[\"SPARK_HOME\"], 'python'))\n",
    "\n",
    "# import package\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "import string\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.ui.port\", 9564)\n",
    "sc = SparkContext(conf=conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdata = sc.textFile(\"/data/MSA_8050_Spring_18/proj08/yelp_combined.csv\").map(lambda x: x.split('^'))\n",
    "header=rawdata.first()\n",
    "rawdata1=(rawdata.filter(lambda x: x!= header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_en = []\n",
    "for word in stopwords.words('english'):\n",
    "    stopwords_en = stopwords_en + [unicodedata.normalize('NFKD', word).encode('ascii','ignore')]\n",
    "stopwords_en\n",
    "\n",
    "def stopwordremover(query):\n",
    "    querywords = query.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in stopwords_en]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a dictionary to remove punctuation from unicode strings\n",
    "remove_punctuation_map = {}\n",
    "\n",
    "for word in string.punctuation:\n",
    "    remove_punctuation_map[ord(word)]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating new list element without punctuation\n",
    "rawdata1 = rawdata1.map(lambda x: x + [x[5].translate(remove_punctuation_map).lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdata1 = rawdata1.map(lambda x: x + [stopwordremover(unicodedata.normalize('NFKD', x[9]).encode('ascii','ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "keyvaluepair2 = rawdata1.map(lambda x: (float(x[3]), x[6].encode('utf-8').split()))\n",
    "keyvaluepair3 = keyvaluepair2.flatMapValues(lambda x: x)\n",
    "keyvaluepair4 = keyvaluepair3.map(lambda x: ((x[0], x[1]),1))\n",
    "#kvp4= sc.parallelize(keyvaluepair4.take(16000))\n",
    "\n",
    "keyvaluepair5 = keyvaluepair4.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "keyvaluepair5.take(5)\n",
    "\n",
    "\n",
    "\n",
    "#Creating key, value pair where key = star rating and value is (Count of word with respect to star rating, word)\n",
    "keyvaluepair6 = keyvaluepair5.map(lambda x: (x[0][0], (x[1], x[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Sorting the values and taking the top 10 words based on frequency\n",
    "keyvaluepair7 = keyvaluepair6.groupByKey().mapValues(lambda x: list(x)).map(lambda x: (x[0], sorted(x[1], reverse=True)[0:10]))                             .sortByKey() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Printing the results\n",
    "print 'Top 10 common words'      + '\\n' + str(keyvaluepair7.collect()[0][0]) + ' star rating :  ' + str(keyvaluepair7.collect()[0][1]) \n",
    "+ '\\n' + str(keyvaluepair7.collect()[1][0]) + ' star rating :  ' + str(keyvaluepair7.collect()[1][1])\n",
    "+ '\\n' + str(keyvaluepair7.collect()[2][0]) + ' star rating :  ' + str(keyvaluepair7.collect()[2][1]) \n",
    "+ '\\n' + str(keyvaluepair7.collect()[3][0]) + ' star rating :  ' + str(keyvaluepair7.collect()[3][1])\n",
    "+ '\\n' + str(keyvaluepair7.collect()[4][0]) + ' star rating :  ' + str(keyvaluepair7.collect()[4][1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Italian_wordcount = results[map(lambda x: \"Italian\" in x,combined['categories'])]\n",
    "American_wordcount = results[map(lambda x: \"American\" in x,combined['categories'])]\n",
    "Mexican_wordcount = results[map(lambda x: \"Mexican\" in x,combined['categories'])]\n",
    "Chinese_wordcount = results[map(lambda x: \"Chinese\" in x,combined['categories'])]\n",
    "Indian_wordcount = results[map(lambda x: \"Indian\" in x,combined['categories'])]\n",
    "#Get the wordcounts by restaurant category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive = open('positive-words.txt').read().split()\n",
    "negative = open('negative-words.txt').read().split()\n",
    "#load positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Italian_wordcount = pd.DataFrame(Italian_wordcount,columns=['count'])\n",
    "American_wordcount = pd.DataFrame(American_wordcount,columns=['count'])\n",
    "Mexican_wordcount = pd.DataFrame(Mexican_wordcount,columns=['count'])\n",
    "Chinese_wordcount = pd.DataFrame(Chinese_wordcount,columns=['count'])\n",
    "Indian_wordcount = pd.DataFrame(Indian_wordcount,columns=['count'])\n",
    "#subset wordcount by restaurant time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Italian\"\n",
    "print np.sum(Italian_wordcount[Italian_wordcount.index.isin(positive)]['count'])\n",
    "print \"American\"\n",
    "print np.sum(American_wordcount[American_wordcount.index.isin(positive)])\n",
    "print \"Mexican\"\n",
    "print np.sum(Mexican_wordcount[Mexican_wordcount.index.isin(positive)])\n",
    "print \"Chinese\"\n",
    "print np.sum(Chinese_wordcount[Chinese_wordcount.index.isin(positive)])\n",
    "print \"Indian\"\n",
    "print np.sum(Indian_wordcount[Indian_wordcount.index.isin(positive)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Italian\"\n",
    "print np.sum(Italian_wordcount[Italian_wordcount.index.isin(negative)])\n",
    "print \"American\"\n",
    "print np.sum(American_wordcount[American_wordcount.index.isin(negative)])\n",
    "print \"Mexican\"\n",
    "print np.sum(Mexican_wordcount[Mexican_wordcount.index.isin(negative)])\n",
    "print \"Chinese\"\n",
    "print np.sum(Chinese_wordcount[Chinese_wordcount.index.isin(negative)])\n",
    "print \"Indian\"\n",
    "print np.sum(Indian_wordcount[Indian_wordcount.index.isin(negative)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cool words overall\n",
    "cool_wordcount = cool.text.str.split(expand=True).stack().value_counts()\n",
    "cool_wordcount = pd.DataFrame(cool_wordcount,columns=['count'])\n",
    "cool_positive = cool_wordcount[cool_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words for cool\n",
    "cool_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words for cool\n",
    "cool_negative = cool_wordcount[cool_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words for cool\n",
    "cool_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#useful words overall\n",
    "useful_wordcount = useful.text.str.split(expand=True).stack().value_counts()\n",
    "useful_wordcount = pd.DataFrame(useful_wordcount,columns=['count'])\n",
    "useful_positive = useful_wordcount[useful_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words for useful\n",
    "useful_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words for useful\n",
    "useful_negative = useful_wordcount[useful_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words for useful\n",
    "useful_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funny words overall\n",
    "funny_wordcount = funny.text.str.split(expand=True).stack().value_counts()\n",
    "funny_wordcount = pd.DataFrame(funny_wordcount,columns=['count'])\n",
    "funny_positive = funny_wordcount[funny_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words for funny\n",
    "funny_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words for funny\n",
    "funny_negative = funny_wordcount[funny_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words for funny\n",
    "funny_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#average length of cool, useful, and funny\n",
    "cool_wc=cool['text'].str.split().str.len().mean()\n",
    "useful_wc=useful['text'].str.split().str.len().mean()\n",
    "funny_wc=funny['text'].str.split().str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top 10 most common words overall\n",
    "print Counter(\" \".join(yelp_review[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#average word count overall\n",
    "overall_wc=yelp_review['text'].str.split().str.len().mean()\n",
    "print \"Average Word Count is: \", overall_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separate data into star ratings\n",
    "star1 = yelp_review[yelp_review['stars_review']==1.]\n",
    "star2 = yelp_review[yelp_review['stars_review']==2.]\n",
    "star3 = yelp_review[yelp_review['stars_review']==3.]\n",
    "star4 = yelp_review[yelp_review['stars_review']==4.]\n",
    "star5 = yelp_review[yelp_review['stars_review']==5.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top 10 words for 1 star\n",
    "Counter(\" \".join(star1[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top 10 words for 2 star\n",
    "Counter(\" \".join(star2[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top 10 words for 3 star\n",
    "Counter(\" \".join(star3[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top 10 words for 4 star\n",
    "Counter(\" \".join(star4[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top 10 words for 5 star\n",
    "Counter(\" \".join(star5[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#average word count by star rating\n",
    "star1_avg_wc=star1['text'].str.split().str.len().mean()\n",
    "star2_avg_wc=star2['text'].str.split().str.len().mean()\n",
    "star3_avg_wc=star3['text'].str.split().str.len().mean()\n",
    "star4_avg_wc=star4['text'].str.split().str.len().mean()\n",
    "star5_avg_wc=star5['text'].str.split().str.len().mean()\n",
    "\n",
    "print \"1 Star Average Word Count is:\", star1_avg_wc\n",
    "print \"2 Star Average Word Count is:\", star2_avg_wc\n",
    "print \"3 Star Average Word Count is:\", star3_avg_wc\n",
    "print \"4 Star Average Word Count is:\", star4_avg_wc\n",
    "print \"5 Star Average Word Count is:\", star5_avg_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lexicon of positive words/sentiments\n",
    "list_positive = open(\"positive-words.txt\").read().split()\n",
    "list_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lexicon of negative words/sentiments\n",
    "list_negative = open(\"negative-words.txt\").read().split()\n",
    "list_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#positive words overall\n",
    "overall_wordcount = yelp_review.text.str.split(expand=True).stack().value_counts()\n",
    "overall_wordcount = pd.DataFrame(overall_wordcount,columns=['count'])\n",
    "overall_positive = overall_wordcount[overall_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words overall\n",
    "overall_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words overall\n",
    "overall_negative = overall_wordcount[overall_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words overall\n",
    "overall_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#positive words onestar\n",
    "onestar_wordcount = star1.text.str.split(expand=True).stack().value_counts()\n",
    "onestar_wordcount = pd.DataFrame(onestar_wordcount,columns=['count'])\n",
    "onestar_positive = onestar_wordcount[onestar_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words onestar\n",
    "onestar_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words onestar\n",
    "onestar_negative = onestar_wordcount[onestar_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words onestar\n",
    "onestar_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#positive words twostar\n",
    "twostar_wordcount = star2.text.str.split(expand=True).stack().value_counts()\n",
    "twostar_wordcount = pd.DataFrame(twostar_wordcount,columns=['count'])\n",
    "twostar_positive = twostar_wordcount[twostar_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words twostar\n",
    "twostar_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words twostar\n",
    "twostar_negative = twostar_wordcount[twostar_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words twostar\n",
    "twostar_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#positive words threestar\n",
    "threestar_wordcount = star3.text.str.split(expand=True).stack().value_counts()\n",
    "threestar_wordcount = pd.DataFrame(threestar_wordcount,columns=['count'])\n",
    "threestar_positive = threestar_wordcount[threestar_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words threestar\n",
    "threestar_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words threestar\n",
    "threestar_negative = threestar_wordcount[threestar_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words threestar\n",
    "threestar_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#positive words fourstar\n",
    "fourstar_wordcount = star4.text.str.split(expand=True).stack().value_counts()\n",
    "fourstar_wordcount = pd.DataFrame(fourstar_wordcount,columns=['count'])\n",
    "fourstar_positive = fourstar_wordcount[fourstar_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words fourstar\n",
    "fourstar_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words fourstar\n",
    "fourstar_negative = fourstar_wordcount[fourstar_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative words fourstar\n",
    "fourstar_negative['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#positive words for fivestar\n",
    "fivestar_wordcount = star5.text.str.split(expand=True).stack().value_counts()\n",
    "fivestar_wordcount = pd.DataFrame(fivestar_wordcount,columns=['count'])\n",
    "fivestar_positive = fivestar_wordcount[fivestar_wordcount.index.isin(list_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of positive words fivestar\n",
    "fivestar_positive['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative words fivestar\n",
    "fivestar_negative = fivestar_wordcount[fivestar_wordcount.index.isin(list_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of negative word fivestar\n",
    "fivestar_negative['count'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
